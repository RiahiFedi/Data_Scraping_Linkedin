{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "no xp\n",
      "duration\n",
      "3\n",
      "no xp\n",
      "duration\n",
      "4\n",
      "name\n",
      "5\n",
      "no xp\n",
      "duration\n",
      "6\n",
      "no xp\n",
      "duration\n",
      "7\n",
      "no xp\n",
      "duration\n",
      "8\n",
      "no xp\n",
      "name\n",
      "duration\n",
      "9\n",
      "no xp\n",
      "duration\n",
      "10\n",
      "no xp\n",
      "name\n",
      "duration\n",
      "11\n",
      "no xp\n",
      "duration\n",
      "12\n",
      "no xp\n",
      "duration\n",
      "13\n",
      "no xp\n",
      "duration\n",
      "14\n",
      "no xp\n",
      "duration\n",
      "15\n",
      "no xp\n",
      "duration\n",
      "16\n",
      "no xp\n",
      "duration\n",
      "17\n",
      "no xp\n",
      "duration\n",
      "18\n",
      "no xp\n",
      "duration\n",
      "19\n",
      "no xp\n",
      "duration\n",
      "20\n",
      "no xp\n",
      "duration\n",
      "21\n",
      "no xp\n",
      "duration\n",
      "22\n",
      "no xp\n",
      "duration\n",
      "23\n",
      "no xp\n",
      "duration\n",
      "24\n",
      "no xp\n",
      "duration\n",
      "25\n",
      "no xp\n",
      "duration\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "no xp\n",
      "name\n",
      "duration\n",
      "30\n",
      "no xp\n",
      "duration\n",
      "31\n",
      "no xp\n",
      "duration\n",
      "32\n",
      "no xp\n",
      "duration\n",
      "33\n",
      "no xp\n",
      "duration\n",
      "34\n",
      "no xp\n",
      "duration\n",
      "35\n",
      "no xp\n",
      "duration\n",
      "36\n",
      "no xp\n",
      "duration\n",
      "37\n",
      "no xp\n",
      "duration\n",
      "38\n",
      "no xp\n",
      "duration\n",
      "39\n",
      "no xp\n",
      "duration\n",
      "40\n",
      "no xp\n",
      "duration\n",
      "41\n",
      "no xp\n",
      "duration\n",
      "42\n",
      "no xp\n",
      "duration\n",
      "43\n",
      "no xp\n",
      "duration\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: fedir\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "from time import sleep\n",
    "import parameters \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# if field is present pass if field:pas if field is not present print text else:\n",
    "def validate_field(field):\n",
    "    if type(field) is not str:\n",
    "       field = 'No results'\n",
    "    return field\n",
    "companies_info = pd.read_csv('companies_info_full.csv')\n",
    "'''companies_info =pd.DataFrame(data= {\n",
    "    'field':[],\n",
    "    'comp_url':[],\n",
    "    'nbr_employees':[]\n",
    "    })'''\n",
    "\n",
    "info = {'name' : [],\n",
    "    'profile_title' : [], \n",
    "    'entreprise_name' : [],\n",
    "    'duration' : [],\n",
    "    'experience' : [],\n",
    "    'location' : [],\n",
    "    'education' : [],\n",
    "    'nbr_employees' :[],\n",
    "    'work_field' :[],\n",
    "    'linkedin_url': []\n",
    "    }\n",
    "profiles_so_far = 0\n",
    "# specifies the path to the chromedriver.exe\n",
    "driver = webdriver.Chrome('C:/Users/fedir/Data_Scraping_Linkedin/chromedriver')\n",
    "\n",
    "\n",
    "# driver.get method() will navigate to a page given by the URL address\n",
    "driver.get('https://www.linkedin.com')\n",
    "\n",
    "# locate email form by_class_name\n",
    "username = driver.find_element_by_id('session_key')\n",
    "\n",
    "# send_keys() to simulate key strokes\n",
    "username.send_keys(parameters.linkedin_username)\n",
    "\n",
    "# sleep for 0.5 seconds\n",
    "sleep(random.randint(500,1000)/1000)\n",
    "\n",
    "# locate password form by_class_name\n",
    "password = driver.find_element_by_id('session_password')\n",
    "\n",
    "# send_keys() to simulate key strokes\n",
    "password.send_keys(parameters.linkedin_password)\n",
    "sleep(random.randint(500,1000)/1000)\n",
    "\n",
    "# locate submit button by_xpath\n",
    "sign_in_button = driver.find_element_by_class_name('sign-in-form__submit-button')\n",
    "\n",
    "# .click() to mimic button click\n",
    "sign_in_button.click()\n",
    "\n",
    "\n",
    "\n",
    "def scroll_down():\n",
    "    SCROLL_PAUSE_TIME = random.randint(500,1000)/1000\n",
    "    #height=driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    driver.execute_script(\"window.scrollTo({top: document.body.scrollHeight,left: 0,behavior: 'smooth'});\")\n",
    "    sleep(SCROLL_PAUSE_TIME)\n",
    "    '''while True:\n",
    "        driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "        sleep(SCROLL_PAUSE_TIME)\n",
    "        max_height=driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if max_height == height:\n",
    "            break\n",
    "        height=max_height'''\n",
    "\n",
    "#Getting the collected Linkedin urls\n",
    "'''url_fl = open(parameters.urls_file_name, \"r\")\n",
    "linkedin_urls = []\n",
    "for line in url_fl:\n",
    "  stripped_line = line.strip()\n",
    "  linkedin_urls.append(stripped_line)\n",
    "url_fl.close()'''\n",
    "\n",
    "#Getting reactions Linkedin urls\n",
    "url_data = pd.read_csv('reactions.csv')\n",
    "linkedin_urls = url_data['linkedin_url']\n",
    "# For loop to iterate over each URL in the list\n",
    "\n",
    "linkedin_url = linkedin_urls[141]\n",
    "\n",
    "\n",
    "for j in range(0,len(linkedin_urls)):\n",
    "  \n",
    "    # get the profile URL \n",
    "    #driver.get(linkedin_url)\n",
    "    driver.get(linkedin_urls[j])\n",
    "    \n",
    "    # add a 5 second pause loading each URL\n",
    "    for i in range(3):\n",
    "        sleep(random.randint(500,1000)/1000)\n",
    "        scroll_down()\n",
    "    \n",
    "    # assigning the source code for the webpage to variable sel\n",
    "    sel = driver.page_source\n",
    "    soup = BeautifulSoup(sel, 'lxml')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        exp_section=soup.find('section',{'id' : 'experience-section'})\n",
    "        if len( exp_section.find_all('div',{'class' : 'pv-experience-section__see-more pv-profile-section__actions-inline ember-view'})) > 0:\n",
    "            # locate the reactions pannel\n",
    "            #more_pannel = driver.find_element_by_class_name('pv-experience-section__see-more pv-profile-section__actions-inline ember-view')\n",
    "            more_pannel = driver.find_element(By.XPATH, '//*[@class=\"pv-experience-section__see-more pv-profile-section__actions-inline ember-view\"]')\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(more_pannel).perform()\n",
    "            more_pannel = more_pannel.find_elements(By.XPATH, '//*[@class=\"pv-profile-section__see-more-inline pv-profile-section__text-truncate-toggle artdeco-button artdeco-button--tertiary artdeco-button--muted\"]')[-1]\n",
    "            actions = ActionChains(driver)\n",
    "            more_pannel.click()\n",
    "        \n",
    "        sel = driver.page_source\n",
    "        soup = BeautifulSoup(sel, 'lxml')\n",
    "    except AttributeError:\n",
    "        print('no xp')\n",
    "    #name_div=soup.find('div',{'class' : 'flex-1 mr5'})\n",
    "    \n",
    "        \n",
    "    try:\n",
    "        name_div=soup.find('div',{'class' : 'pv-text-details__left-panel mr5'})\n",
    "        name_loc=name_div.find_all('div')\n",
    "        \n",
    "        name=name_loc[0].h1.text.strip()\n",
    "        profile_title=name_loc[1].text.strip()\n",
    "        location=name_loc[2].span.text.strip()\n",
    "        \n",
    "        big_div = soup.find('ul',{'class' : 'pv-text-details__right-panel'})\n",
    "        place_holder = big_div.find_all('li')\n",
    "        #place_holder = work_div[1].find_all('a', {'class' : 'pv-top-card--experience-list-item'})\n",
    "        \n",
    "        if len(place_holder)>1:\n",
    "            entreprise_name = place_holder[0].a.h2.div.text.strip()\n",
    "            education = place_holder[1].a.h2.div.text.strip()\n",
    "        elif len(place_holder) == 1 :\n",
    "            test = place_holder[0].a.h2.div['aria-label']\n",
    "            if test == 'Current company':\n",
    "                entreprise_name = place_holder[0].a.h2.div.text.strip()\n",
    "                education = ''\n",
    "            elif test == 'Education':\n",
    "                education = place_holder[0].a.h2.div.text.strip()\n",
    "                entreprise_name = 'Currently Unemployed'\n",
    "        else: \n",
    "            education = ''\n",
    "            entreprise_name = 'Currently Unemployed'\n",
    "    except AttributeError:\n",
    "        print('name') \n",
    "        \n",
    "    try:\n",
    "        exp_section=soup.find('section',{'id' : 'experience-section'}).ul.li\n",
    "        if not exp_section.find_all('ul'):\n",
    "        #place_holder = exp_section.find_all('div',{'class' : 'pv-entity__summary-info pv-entity__summary-info--background-section mb2'})\n",
    "            place_holder = exp_section.find('h4')\n",
    "            place_holder = place_holder.find_all('span')\n",
    "            Duration = place_holder[1].text.strip()\n",
    "        else:\n",
    "            place_holder = exp_section.find_all('ul')[0].find_all('li')\n",
    "            \n",
    "            if len(place_holder[0].find_all('div',{'class' : 'display-flex'})) > 1 :\n",
    "                last_ = place_holder[0].find_all('div',{'class' : 'display-flex'})[1].h4.find_all('span')[1].text.strip()\n",
    "                first_ = place_holder[-1].find_all('div',{'class' : 'display-flex'})[1].h4.find_all('span')[1].text.strip()\n",
    "                \n",
    "            else:\n",
    "                last_ = place_holder[0].find('div',{'class' : 'display-flex'}).h4.find_all('span')[1].text.strip()\n",
    "                first_ = place_holder[-1].find('div',{'class' : 'display-flex'}).h4.find_all('span')[1].text.strip()\n",
    "            \n",
    "            dates = first_.split('–') + last_.split('–')\n",
    "            Duration = dates[0] + '–' + dates[-1]\n",
    "            \n",
    "    except AttributeError:\n",
    "        print('duration')\n",
    "        Duration=''\n",
    "        #job_title=''\n",
    "        #job_duration=''\n",
    " \n",
    "    '''try:\n",
    "        place_holder =soup.find('section', {'class' : 'pv-profile-section pv-interests-section artdeco-card mt4 p5 ember-view'}).ul\n",
    "        elements = place_holder.find_all('li', {'class' : 'pv-interest-entity pv-profile-section__card-item ember-view'})\n",
    "            \n",
    "    except AttributeError:\n",
    "        interests = '''\n",
    "        \n",
    "    try :\n",
    "        exp_section=soup.find('section',{'id' : 'experience-section'}).ul\n",
    "        job_list = exp_section.find_all('li',{'class':'pv-entity__position-group-pager pv-profile-section__list-item ember-view'})\n",
    "        if not job_list[-1].find_all('ul'):\n",
    "            place_holder = job_list[-1].find('h4')\n",
    "            place_holder = place_holder.find_all('span')\n",
    "            first_job = place_holder[1].text.strip()\n",
    "            dates = first_job.split('–') + Duration.split('–')\n",
    "            total_exp = dates[0] + '–' + dates[-1]\n",
    "        else:\n",
    "            place_holder = job_list[-1].find_all('ul')[0].find_all('li')\n",
    "            if len(place_holder[0].find_all('div',{'class' : 'display-flex'})) > 1 :\n",
    "                first_job = place_holder[-1].find_all('div',{'class' : 'display-flex'})[1].h4.find_all('span')[1].text.strip()\n",
    "                \n",
    "            else:\n",
    "                first_job = place_holder[-1].find('div',{'class' : 'display-flex'}).h4.find_all('span')[1].text.strip()\n",
    "            \n",
    "    except AttributeError: \n",
    "        total_exp = ''       \n",
    "\n",
    "\n",
    "        \n",
    "       \n",
    "        \n",
    "    try :\n",
    "        exp_section = soup.find('section',{'id' : 'experience-section'})\n",
    "        if exp_section.find_all('a',{'class' : 'full-width ember-view'}):\n",
    "            link = exp_section.find_all('a',{'class' : 'full-width ember-view'})[0]['href']\n",
    "        else : raise AttributeError\n",
    "        if link[0:8] != '/company' :\n",
    "            print('no')\n",
    "            work_field = ''\n",
    "            nbr_employees = ''\n",
    "        else: \n",
    "            link = 'https://www.linkedin.com'  + link\n",
    "            if not link in list(companies_info['comp_url']):\n",
    "                driver.get(link)\n",
    "                sleep(random.randint(500,1000)/1000)\n",
    "                scroll_down()\n",
    "                sel = driver.page_source\n",
    "                soup = BeautifulSoup(sel, 'lxml')\n",
    "                work_field = soup.find('div', {'class' : 'org-top-card-summary-info-list__info-item'}).text.strip()\n",
    "                place_holder = soup.find('div', {'class': 'mt1'}).div\n",
    "                nbr_employees = place_holder.find_all('a', {'class' : 'ember-view'})[-1].span.text.strip()\n",
    "                l_temp = re.findall(r'\\b\\d+\\b', nbr_employees)\n",
    "                if len(l_temp)>1:\n",
    "                    nbr_employees = int(l_temp[0])*1000+ int(l_temp[1])\n",
    "                else:\n",
    "                    nbr_employees = int(l_temp[0])\n",
    "                #nbr_employees = [int(s) for s in nbr_employees.split() if s.isdigit()][0]\n",
    "                companies_info =companies_info.append({'field' : work_field,'comp_url': link,'nbr_employees':nbr_employees},ignore_index=True)\n",
    "            else:\n",
    "                nbr_employees = list(companies_info[companies_info['comp_url']==link]['nbr_employees'])[0]\n",
    "                work_field = list(companies_info[companies_info['comp_url']==link]['field'])[0]\n",
    "    except AttributeError:\n",
    "        work_field = ''\n",
    "        nbr_employees = ''\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    info['name'].append(name)\n",
    "    info['profile_title'].append(profile_title)\n",
    "    info['entreprise_name'].append(entreprise_name)\n",
    "    info['duration'].append(Duration)\n",
    "    info['experience'].append(total_exp)\n",
    "    info['location'].append(location)\n",
    "    info['education'].append(education)\n",
    "    info['linkedin_url'].append(linkedin_urls[j])\n",
    "    info['work_field'].append(work_field)\n",
    "    info['nbr_employees'].append(nbr_employees)\n",
    "\n",
    "    \n",
    "    name = None\n",
    "    profile_title = None\n",
    "    entreprise_name = None\n",
    "    Duration = None\n",
    "    location = None\n",
    "    profiles_so_far +=1\n",
    "    print(profiles_so_far)\n",
    "    sleep(random.randint(10,35))\n",
    "   \n",
    "# terminates the application\n",
    "driver.quit()\n",
    "\n",
    "#Saves the data as a csv file\n",
    "df = pd.DataFrame(data=info)\n",
    "companies_info.to_csv('companies_info_full.csv')\n",
    "df.to_csv('results_file.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
